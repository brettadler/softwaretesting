# Using AI for Quality Assurance & Testing

## Use Generative AI for planning and documentation
* Product Requirements
* Test strategies
* Test plans
* Test scripts

## Use AI Coding Assistants
- [Using OpenAI](ai_instructions/openai.md)
- [Using GitHub Copilot](ai_instructions/github_copilot.md)
- [Using Figma Make](ai_instructions/figma.md)
- [Using Antrophic Claude Code](ai_instructions/claude.md)
- [Using Google Gemini](ai_instructions/gemini.md)
- [Using Cursor](ai_instructions/cursor.md)
- Google Jules - https://jules.google
- Vercelâ€™s v0 - https://v0.dev
- Bolt - https://bolt.new
- Perplexity - https://www.perplexity.ai
- Tabnine - https://www.tabnine.com
- Windsurf Editor - https://windsurf.com
- JetBrains AI - https://www.jetbrains.com
- Cline - https://cline.bot
- Supermaven - https://supermaven.com
- CodeRqbbit - https://www.coderabbit.ai

## Use Trained AI Models to Test Software
* QA Bots

## Use AI to Test AI
* AI's that test software
* Models and training
* Chatbots and voicebots

## Communication Preferences

### Code Explanations
- Start with high-level approach, then dive into implementation details
- Explain the "why" behind architectural decisions
- Provide alternative approaches when relevant
- Include potential trade-offs and considerations

### Problem-Solving Approach
1. Understand the requirements fully
2. Consider existing patterns in the codebase
3. Propose solution with reasoning
4. Discuss potential issues or edge cases
5. Provide implementation with proper testing

### Questions and Clarifications
- Ask for clarification when requirements are ambiguous
- Suggest improvements to existing code when relevant
- Point out potential issues before they become problems
- Recommend best practices and industry standards

## References
- [AI Enablement Stack](https://github.com/daytonaio/ai-enablement-stack)
